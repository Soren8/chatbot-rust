# TTS Streaming Implementation Summary

## Objective
Enable low-latency, real-time text-to-speech (TTS) streaming for the "Kokoro" and "Fish Speech" providers, replacing the previous implementation that buffered the entire audio file before playback.

## Challenges & Solutions

### 1. The Buffering Bottleneck
**Issue:** The initial architecture waited for the complete audio file to be generated by the backend before sending it to the client. The frontend similarly waited for the full `blob` before creating an `Audio` element.
**Resolution:** 
- **Backend:** Updated `handle_tts` to proxy the backend response stream directly to the client using chunked transfer encoding.
- **Frontend:** Refactored `playTTS` to process the stream as chunks arrive.

### 2. Audio Artifacts (Clicking & Popping)
**Issue:** Concatenating raw PCM chunks or independent WAV files in the browser caused audible clicks and pops.
- **Cause 1 (Discontinuities):** If one chunk ends at a high amplitude and the next starts at zero (or vice-versa), the sudden voltage jump creates a click.
- **Cause 2 (Double Headering):** The server was blindly prepending a WAV header to the stream. When the upstream provider (Kokoro) also returned a WAV file, the stream contained a header *inside* the audio data, interpreted as noise/clicks.
- **Cause 3 (Scheduling Jitter):** Using standard `setTimeout` or multiple `Audio` elements resulted in gaps between playback segments due to the imprecise nature of the main JavaScript thread.

**Resolution:**
- **Header Stripping:** The backend now inspects the upstream response. If it detects a "RIFF" (WAV) header, it strips the first 44 bytes to isolate the raw PCM data.
- **Crossfading:** The backend applies a **5ms linear fade-in and fade-out** to the raw PCM stream. This ensures every segment starts and ends at zero amplitude (zero-crossing), eliminating boundary clicks.
- **Gapless Scheduling:** The frontend was refactored to use a single `AudioContext`. Instead of playing independent chunks, it schedules decoded audio buffers on a continuous timeline (`nextStartTime`), ensuring sample-accurate transitions.

### 3. Browser Streaming Limitations
**Issue:** Browsers cannot natively stream audio from `POST` requests into an `<audio>` tag or `AudioContext` without complex workarounds (like `AudioWorklet` or `MediaSource`, which has poor WAV support). `POST` was required for the TTS API to handle long text and security tokens.

**Resolution: The "Pre-sign" Pattern**
We implemented a two-step architecture:
1.  **Submission (`POST /tts`):** The frontend submits the text and CSRF token. The server caches the request and returns a temporary, single-use **token**.
2.  **Streaming (`GET /tts_stream/{token}`):** The frontend uses the token to fetch the audio via a standard `GET` request.

This approach allows us to use `fetch` with `decodeAudioData` (which works best with complete files/segments) on a per-sentence basis, combining the low latency of streaming with the reliability of native browser decoding.

### 4. Latency
**Issue:** Initial attempts included artificial delays (100ms-300ms) to buffer data against network jitter.
**Resolution:** With the robust `AudioContext` scheduling, these artificial delays were removed. The scheduler detects if the "next start time" is in the past (i.e., we are buffering) and plays the audio immediately, ensuring the lowest possible latency.

## Final Architecture

1.  **Frontend:** Splits text into sentences.
2.  **Frontend:** Iteratively `POST`s each sentence to get a token.
3.  **Frontend:** Fetches audio for the token via `GET`.
4.  **Backend:** Fetches audio from upstream, strips headers, applies fades, prepends a new valid WAV header, and streams it.
5.  **Frontend:** Decodes the WAV and schedules it on the `AudioContext` timeline for seamless playback.
